{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Report of Permuted MNIST Challenge"
      ],
      "metadata": {
        "id": "l2oCbQegbkoD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For clearing the old environment before loading the latest one\n",
        "\n",
        "!rm -rf /content/SD\n",
        "!rm -rf /content/permuted_mnist"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "-jki0QJafGgc",
        "outputId": "508529f8-e221-4ac2-ab5a-6dbc5ac4405b"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'SD'...\n",
            "remote: Enumerating objects: 164, done.\u001b[K\n",
            "remote: Counting objects: 100% (164/164), done.\u001b[K\n",
            "remote: Compressing objects: 100% (131/131), done.\u001b[K\n",
            "remote: Total 164 (delta 57), reused 112 (delta 18), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (164/164), 12.54 MiB | 10.48 MiB/s, done.\n",
            "Resolving deltas: 100% (57/57), done.\n",
            "Cloning into 'permuted_mnist'...\n",
            "remote: Enumerating objects: 194, done.\u001b[K\n",
            "remote: Counting objects: 100% (194/194), done.\u001b[K\n",
            "remote: Compressing objects: 100% (134/134), done.\u001b[K\n",
            "remote: Total 194 (delta 77), reused 163 (delta 50), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (194/194), 12.62 MiB | 10.96 MiB/s, done.\n",
            "Resolving deltas: 100% (77/77), done.\n",
            "‚úÖ ÁéØÂ¢ÉÂ∑≤Ê∏ÖÁêÜÂπ∂ÈáçÊñ∞ÂØºÂÖ•ÂÆåÊØï„ÄÇ\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/tiphddddd/SD\n",
        "!git clone https://github.com/ml-arena/permuted_mnist.git\n",
        "import sys\n",
        "sys.path.append('/content/SD')\n",
        "import sys\n",
        "sys.path.append('/content/permuted_mnist')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "bcCg8ldX6dMP",
        "outputId": "ef905206-b406-4310-9f64-390cccccf7fa"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'SD' already exists and is not an empty directory.\n",
            "fatal: destination path 'permuted_mnist' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "from typing import Dict, List\n",
        "import torch\n",
        "\n",
        "# Import the environment and agents\n",
        "from permuted_mnist.env.permuted_mnist import PermutedMNISTEnv\n",
        "\n",
        "# Create environment with 10 episodes (tasks)\n",
        "env = PermutedMNISTEnv(number_episodes=10)\n",
        "\n",
        "# Set seed for reproducibility\n",
        "env.set_seed(42)\n",
        "\n",
        "print(f\"Environment created with {env.number_episodes} permuted tasks\")\n",
        "print(f\"Training set size: {env.train_size} samples\")\n",
        "print(f\"Test set size: {env.test_size} samples\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "6r7utzVq8OEE",
        "outputId": "41230295-c79d-4902-8f3f-97c28ec318f7"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Environment created with 10 permuted tasks\n",
            "Training set size: 60000 samples\n",
            "Test set size: 10000 samples\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚Ö†  Problem Statement\n",
        "\n",
        "This challenge is based on the **Permuted MNIST** dataset, which represents a typical **fast-adaptation meta-learning** scenario.  \n",
        "Unlike the traditional MNIST handwritten digit classification task, Permuted MNIST introduces two types of random permutations for each task:\n",
        "\n",
        "### 1Ô∏è‚É£ Pixel Permutation\n",
        "The 784 pixels of each input image are randomly shuffled, destroying the original spatial structure. Different tasks use different permutation patterns, so the model cannot rely on convolutional spatial priors.\n",
        "\n",
        "### 2Ô∏è‚É£ Label Permutation\n",
        "The digit labels in each task are remapped (for example, all ‚Äú3‚Äùs become ‚Äú7‚Äùs, and all ‚Äú7‚Äùs become ‚Äú1‚Äùs). This means the model must ‚Äúrelearn from scratch‚Äù the class-to-label correspondence in every new task.\n",
        "\n",
        "### ‚öôÔ∏è System Constraints\n",
        "- üíª **Computation**: CPU only (2 cores), 4GB memory.  \n",
        "- ‚è± **Time constraint**: The total training and inference time per task must be kept within **1 minute**.\n",
        "\n",
        "Hence, the core goal of this challenge is:  \n",
        "> **To design a learning algorithm capable of fast convergence and stable generalization under extremely limited computational resources.**\n"
      ],
      "metadata": {
        "id": "mf32Fu8TM9uP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ‚Ö° Methodology\n",
        "\n",
        "To tackle the dual challenges of **pixel permutation** and **label permutation** in the Permuted MNIST task, this project follows a systematic, **‚Äúsimple-to-advanced, step-by-step optimization‚Äù** strategy.  \n",
        "The process ultimately results in a balanced and efficient model: the **TorchMLP Agent**.  \n",
        "Below is a record of the model‚Äôs evolution from the baseline to the final optimized version.\n",
        "\n",
        "\n",
        "### 1Ô∏è‚É£ Baseline Exploration\n",
        "\n",
        "#### (1) Random and Linear Models\n",
        "- **Random Predictor**: Used as a zero baseline to verify the environment interface and evaluation pipeline.  \n",
        "- **Linear Classifier**: A single-layer softmax regression model with L2 regularization.  \n",
        "  - Performs decently under a fixed permutation (~70%) but generalizes poorly across tasks.\n",
        "\n",
        "#### (2) Initial MLP Design\n",
        "- **TorchMLP**: Two fully connected layers `100 ‚Üí 100 ‚Üí 10` with ReLU activation.  \n",
        "  - Training parameters: `epochs=3, batch_size=128`.  \n",
        "  - This serves as the starting point for later improvements.\n",
        "\n",
        "\n",
        "### 2Ô∏è‚É£ Feature Engineering (FE)\n",
        "\n",
        "To reduce brightness and amplitude variations between different permutation tasks and improve robustness, the following lightweight preprocessing is applied:  \n",
        "- **Pixel Normalization**: If input range is `[0,255]`, rescale to `[0,1]`.  \n",
        "- **Per-sample L2 Normalization**: Each sample is normalized by its L2 norm to mitigate intensity variation (acts like brightness adjustment).  \n",
        "\n",
        "\n",
        "### 3Ô∏è‚É£ Improvement of the Model Structure (IMS)\n",
        "\n",
        "#### (1) Expanded Hidden Dimensions\n",
        "- The early structure `100‚Üí100` is expanded to `256‚Üí128` to enhance nonlinear representation capacity.\n",
        "\n",
        "#### (2) BatchNorm + Activation Enhancement\n",
        "- Add **Batch Normalization** after each linear layer to stabilize training.  \n",
        "- Activation combination: use **SiLU** in the first layer (smooth gradients, faster convergence) and **ReLU** in the second (better sparsity).\n",
        "\n",
        "#### (3) Residual Bottleneck Block\n",
        "- Introduce a lightweight residual block within the 256-dimensional layer: `256 ‚Üí 64 ‚Üí 256`.  \n",
        "- Structure: `BN ‚Üí SiLU ‚Üí Linear ‚Üí BN ‚Üí SiLU ‚Üí Linear`, followed by a pre-activation residual connection `x + h`.\n",
        "\n",
        "#### (4) Regularization on the Classification Head\n",
        "- Apply **Weight Normalization** to the final layer `Linear(128‚Üí10)` to reduce scale instability.  \n",
        "- Disable it before quantization for compatibility.\n",
        "\n",
        "> In addition, **Label Smoothing (Œµ=0.05)** is introduced to prevent overconfidence on single labels and improve generalization across label-permuted tasks.\n",
        "\n",
        "\n",
        "### 4Ô∏è‚É£ Optimizer (OP)\n",
        "\n",
        "#### Comparison and Selection\n",
        "- Compared **Adam**, **SGD**, and **RMSprop**:\n",
        "  - Adam: fast convergence but unstable oscillations;  \n",
        "  - SGD: stable but slow;  \n",
        "  - ‚úÖ **RMSprop**: balanced speed and smoothness on CPU ‚Äî selected as the final optimizer. Adding a **Cosine Annealing scheduler** further smooths the loss curve and stabilizes validation accuracy.\n",
        "\n",
        "\n",
        "### 5Ô∏è‚É£ Model Compression (MC)\n",
        "\n",
        "To further improve inference speed and efficiency under CPU constraints, two lightweight compression techniques were tested:  \n",
        "- **Dynamic INT8 Quantization**: Apply dynamic quantization to all linear layers, achieving significant acceleration with negligible accuracy loss.  \n",
        "- **Prune40% + INT8**: Perform 40% pruning before quantization ‚Äî faster inference but with slight accuracy degradation.  \n",
        "\n",
        "The final deployment uses **Dynamic INT8 Quantization**, which preserves stable accuracy while greatly accelerating inference.\n",
        "\n",
        "\n",
        "### 6Ô∏è‚É£ Hyperparameter Tuning and Final Configuration\n",
        "\n",
        "A grid search was conducted over:  \n",
        "`epochs ‚àà {5, 7, 10, 15}`, `batch_size ‚àà {100, 128}`  \n",
        "\n",
        "Final choice:  \n",
        "> **epochs = 10**, **batch_size = 128**\n",
        "\n",
        "This configuration achieves over **98.5% accuracy**  \n",
        "while keeping total runtime per task within **35‚Äì38 seconds (CPU mode)**.\n"
      ],
      "metadata": {
        "id": "gvADMwtGcqGs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚Ö°.From Baselines to the Final Model Evolution Path"
      ],
      "metadata": {
        "id": "N9e4pn0Rdc4y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1Ô∏è‚É£ Baseline Exploration\n",
        "\n",
        "#### (1) Random and Linear Models\n",
        "- **Random Predictor**: Serves as a zero baseline to verify the environment interface and evaluation process;\n"
      ],
      "metadata": {
        "id": "6YoXBBrm_B_C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from SD.models.random import Agent as RandomAgent\n",
        "\n",
        "# Reset environment for fresh start\n",
        "env.reset()\n",
        "env.set_seed(42)\n",
        "\n",
        "# Create random agent\n",
        "random_agent = RandomAgent(output_dim=10, seed=42)\n",
        "\n",
        "# Track performance\n",
        "random_accuracies = []\n",
        "random_times = []\n",
        "\n",
        "print(\"Evaluating Random Agent (Baseline)\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Evaluate on all tasks\n",
        "task_num = 1\n",
        "while True:\n",
        "    task = env.get_next_task()\n",
        "    if task is None:\n",
        "        break\n",
        "\n",
        "    start_time = time.time()\n",
        "    random_agent.train(task['X_train'], task['y_train'])\n",
        "    predictions = random_agent.predict(task['X_test'])\n",
        "    elapsed_time = time.time() - start_time\n",
        "    accuracy = env.evaluate(predictions, task['y_test'])\n",
        "\n",
        "    random_accuracies.append(accuracy)\n",
        "    random_times.append(elapsed_time)\n",
        "\n",
        "    print(f\"Task {task_num}: Accuracy = {accuracy:.2%}, Time = {elapsed_time:.4f}s\")\n",
        "    task_num += 1\n",
        "\n",
        "print(f\"\\nRandom Agent Summary:\")\n",
        "print(f\"  Mean accuracy: {np.mean(random_accuracies):.2%} ¬± {np.std(random_accuracies):.2%}\")\n",
        "print(f\"  Total time: {np.sum(random_times):.2f}s\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Cd1Pw-FK7L7o",
        "outputId": "b7bc2cb9-23e6-44ee-bb99-7262f1783581"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating Random Agent (Baseline)\n",
            "==================================================\n",
            "Task 1: Accuracy = 9.96%, Time = 0.0003s\n",
            "Task 2: Accuracy = 9.70%, Time = 0.0003s\n",
            "Task 3: Accuracy = 10.41%, Time = 0.0004s\n",
            "Task 4: Accuracy = 10.02%, Time = 0.0005s\n",
            "Task 5: Accuracy = 10.23%, Time = 0.0004s\n",
            "Task 6: Accuracy = 9.94%, Time = 0.0003s\n",
            "Task 7: Accuracy = 10.29%, Time = 0.0003s\n",
            "Task 8: Accuracy = 10.27%, Time = 0.0003s\n",
            "Task 9: Accuracy = 9.93%, Time = 0.0003s\n",
            "Task 10: Accuracy = 10.09%, Time = 0.0003s\n",
            "\n",
            "Random Agent Summary:\n",
            "  Mean accuracy: 10.08% ¬± 0.20%\n",
            "  Total time: 0.00s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- **Linear Classifier (Logistic Regression)**: A single-layer softmax regression model with L2 regularization;  \n",
        "  - Performs reasonably well under a fixed permutation (‚âà90%) but generalizes poorly across different tasks.\n"
      ],
      "metadata": {
        "id": "irRcT0EF_K34"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from SD.models.linear import Agent as LinearAgent\n",
        "\n",
        "# Reset environment\n",
        "env.reset()\n",
        "env.set_seed(42)\n",
        "\n",
        "# Create linear agent\n",
        "linear_agent = LinearAgent(input_dim=784, output_dim=10, learning_rate=0.01)\n",
        "\n",
        "# Track performance\n",
        "linear_accuracies = []\n",
        "linear_times = []\n",
        "\n",
        "print(\"Evaluating Linear Agent\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Evaluate on all tasks\n",
        "task_num = 1\n",
        "while True:\n",
        "    task = env.get_next_task()\n",
        "    if task is None:\n",
        "        break\n",
        "    linear_agent.reset()\n",
        "    start_time = time.time()\n",
        "    linear_agent.train(task['X_train'], task['y_train'], epochs=5, batch_size=32)\n",
        "    predictions = linear_agent.predict(task['X_test'])\n",
        "    elapsed_time = time.time() - start_time\n",
        "    accuracy = env.evaluate(predictions, task['y_test'])\n",
        "\n",
        "    linear_accuracies.append(accuracy)\n",
        "    linear_times.append(elapsed_time)\n",
        "\n",
        "    print(f\"Task {task_num}: Accuracy = {accuracy:.2%}, Time = {elapsed_time:.2f}s\")\n",
        "    task_num += 1\n",
        "\n",
        "print(f\"\\nLinear Agent Summary:\")\n",
        "print(f\"  Mean accuracy: {np.mean(linear_accuracies):.2%} ¬± {np.std(linear_accuracies):.2%}\")\n",
        "print(f\"  Total time: {np.sum(linear_times):.2f}s\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "Y-eCTJc3-d8b",
        "outputId": "3e6e8c54-f4e2-4ca9-e6c8-dee1f225d888"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating Linear Agent\n",
            "==================================================\n",
            "Task 1: Accuracy = 90.77%, Time = 2.98s\n",
            "Task 2: Accuracy = 90.68%, Time = 4.04s\n",
            "Task 3: Accuracy = 90.73%, Time = 3.15s\n",
            "Task 4: Accuracy = 90.79%, Time = 3.93s\n",
            "Task 5: Accuracy = 90.62%, Time = 2.92s\n",
            "Task 6: Accuracy = 90.92%, Time = 3.39s\n",
            "Task 7: Accuracy = 90.87%, Time = 2.96s\n",
            "Task 8: Accuracy = 90.79%, Time = 2.98s\n",
            "Task 9: Accuracy = 90.70%, Time = 3.69s\n",
            "Task 10: Accuracy = 90.84%, Time = 2.92s\n",
            "\n",
            "Linear Agent Summary:\n",
            "  Mean accuracy: 90.77% ¬± 0.09%\n",
            "  Total time: 32.98s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### (2) Initial MLP Design\n",
        "- **TorchMLP**: Building upon the LinearAgent, we aimed for a stronger starting point.  \n",
        "  A two-layer fully connected network `100 ‚Üí 100 ‚Üí 10` with ReLU activation was implemented,  \n",
        "  trained with parameters `epochs=3, batch_size=128`.  \n",
        "  This lightweight TorchMLP achieved promising results and served as the foundation for subsequent optimizations.\n"
      ],
      "metadata": {
        "id": "bxzVRv0Z_r7K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from SD.models.torchmlp import Agent as TorchMLP\n",
        "\n",
        "# Reset environment\n",
        "env.reset()\n",
        "env.set_seed(42)\n",
        "\n",
        "# Create MLP agent\n",
        "mlp_agent = TorchMLP(\n",
        "    output_dim=10,\n",
        "    seed=42,\n",
        "    hidden_sizes=[100, 100],\n",
        "    n_epochs=3,\n",
        "    batch_size=128\n",
        ")\n",
        "\n",
        "mlp_agent.verbose = False\n",
        "\n",
        "# Track performance\n",
        "mlp_accuracies = []\n",
        "mlp_times = []\n",
        "\n",
        "print(\"Evaluating TorchMLP Agent (100‚Üí100‚Üí10, epochs=3, batch=128)\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Evaluate on all tasks\n",
        "task_num = 1\n",
        "while True:\n",
        "    task = env.get_next_task()\n",
        "    if task is None:\n",
        "        break\n",
        "\n",
        "    mlp_agent.reset()\n",
        "    start_time = time.time()\n",
        "    mlp_agent.verbose = False\n",
        "    mlp_agent.train(task['X_train'], task['y_train'])\n",
        "    predictions = mlp_agent.predict(task['X_test'])\n",
        "    elapsed_time = time.time() - start_time\n",
        "    accuracy = env.evaluate(predictions, task['y_test'])\n",
        "\n",
        "    mlp_accuracies.append(accuracy)\n",
        "    mlp_times.append(elapsed_time)\n",
        "\n",
        "    print(f\"Task {task_num}: Accuracy = {accuracy:.2%}, Time = {elapsed_time:.2f}s\")\n",
        "    task_num += 1\n",
        "\n",
        "print(f\"\\nTorchMLP Agent Summary:\")\n",
        "print(f\"  Mean accuracy: {np.mean(mlp_accuracies):.2%} ¬± {np.std(mlp_accuracies):.2%}\")\n",
        "print(f\"  Total time: {np.sum(mlp_times):.2f}s\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "EjKncIti_MaU",
        "outputId": "513bc6f7-d5f5-4956-bfa7-9ffd5c588ea2"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating TorchMLP Agent (100‚Üí100‚Üí10, epochs=3, batch=128)\n",
            "==================================================\n",
            "Task 1: Accuracy = 97.31%, Time = 5.80s\n",
            "Task 2: Accuracy = 97.40%, Time = 4.90s\n",
            "Task 3: Accuracy = 97.55%, Time = 5.18s\n",
            "Task 4: Accuracy = 97.13%, Time = 5.87s\n",
            "Task 5: Accuracy = 97.47%, Time = 6.03s\n",
            "Task 6: Accuracy = 97.45%, Time = 6.72s\n",
            "Task 7: Accuracy = 97.45%, Time = 5.50s\n",
            "Task 8: Accuracy = 97.44%, Time = 5.80s\n",
            "Task 9: Accuracy = 97.37%, Time = 7.05s\n",
            "Task 10: Accuracy = 97.34%, Time = 6.00s\n",
            "\n",
            "TorchMLP Agent Summary:\n",
            "  Mean accuracy: 97.39% ¬± 0.11%\n",
            "  Total time: 58.87s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2Ô∏è‚É£ Feature Engineering (FE)\n",
        "\n",
        "To reduce brightness and amplitude variations between different permutation tasks and improve robustness, the following lightweight preprocessing is applied:  \n",
        "- **Pixel Normalization**: If input range is `[0,255]`, rescale to `[0,1]`.  \n",
        "- **Per-sample L2 Normalization**: Each sample is normalized by its L2 norm to mitigate intensity variation (acts like brightness adjustment).  \n",
        "\n"
      ],
      "metadata": {
        "id": "lbaLZeo3Geir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from SD.utils.data import _as_float_01,_l2_per_sample\n",
        "\n",
        "def _to_numpy(x):\n",
        "    if isinstance(x, torch.Tensor):\n",
        "        return x.detach().cpu().numpy()\n",
        "    return x\n",
        "\n",
        "def _fe_for_agent(x):\n",
        "    x01 = _as_float_01(x)\n",
        "    xl2 = _l2_per_sample(x01)\n",
        "    xl2 = _to_numpy(xl2)\n",
        "    return (xl2 * 255.0).astype(np.float32)\n",
        "\n",
        "# Reset environment\n",
        "env.reset()\n",
        "env.set_seed(42)\n",
        "\n",
        "# Create MLP agent\n",
        "mlp_agent = TorchMLP(\n",
        "    output_dim=10,\n",
        "    seed=42,\n",
        "    hidden_sizes=[100, 100],\n",
        "    n_epochs=3,\n",
        "    batch_size=128\n",
        ")\n",
        "mlp_agent.verbose = False\n",
        "\n",
        "# Track performance\n",
        "mlp_accuracies = []\n",
        "mlp_times = []\n",
        "\n",
        "print(\"Evaluating TorchMLP Agent + FE (100‚Üí100‚Üí10, epochs=3, batch=128)\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Evaluate on all tasks\n",
        "task_num = 1\n",
        "while True:\n",
        "    task = env.get_next_task()\n",
        "    if task is None:\n",
        "        break\n",
        "\n",
        "    # ---- Apply FE ----\n",
        "    Xtr = _fe_for_agent(task['X_train'])\n",
        "    Xte = _fe_for_agent(task['X_test'])\n",
        "\n",
        "    mlp_agent.reset()\n",
        "    start_time = time.time()\n",
        "    mlp_agent.verbose = False\n",
        "    mlp_agent.train(Xtr, task['y_train'])\n",
        "    predictions = mlp_agent.predict(Xte)\n",
        "    elapsed_time = time.time() - start_time\n",
        "    accuracy = env.evaluate(predictions, task['y_test'])\n",
        "\n",
        "    mlp_accuracies.append(accuracy)\n",
        "    mlp_times.append(elapsed_time)\n",
        "\n",
        "    print(f\"Task {task_num}: Accuracy = {accuracy:.2%}, Time = {elapsed_time:.2f}s\")\n",
        "    task_num += 1\n",
        "\n",
        "print(f\"\\nTorchMLP Agent + FE Summary:\")\n",
        "print(f\"  Mean accuracy: {np.mean(mlp_accuracies):.2%} ¬± {np.std(mlp_accuracies):.2%}\")\n",
        "print(f\"  Total time: {np.sum(mlp_times):.2f}s\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "KYACNk0oGc-y",
        "outputId": "375fd925-e98f-4eab-df44-f933b61cda33"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating TorchMLP Agent + FE (100‚Üí100‚Üí10, epochs=3, batch=128)\n",
            "==================================================\n",
            "Task 1: Accuracy = 97.41%, Time = 5.66s\n",
            "Task 2: Accuracy = 97.41%, Time = 4.78s\n",
            "Task 3: Accuracy = 97.55%, Time = 4.72s\n",
            "Task 4: Accuracy = 97.40%, Time = 5.00s\n",
            "Task 5: Accuracy = 97.49%, Time = 5.58s\n",
            "Task 6: Accuracy = 97.86%, Time = 4.92s\n",
            "Task 7: Accuracy = 97.64%, Time = 4.73s\n",
            "Task 8: Accuracy = 97.35%, Time = 4.76s\n",
            "Task 9: Accuracy = 97.30%, Time = 6.05s\n",
            "Task 10: Accuracy = 97.48%, Time = 5.83s\n",
            "\n",
            "TorchMLP Agent + FE Summary:\n",
            "  Mean accuracy: 97.49% ¬± 0.15%\n",
            "  Total time: 52.05s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3Ô∏è‚É£ Improvement of the Model Structure (IMS)\n",
        "\n",
        "#### (1) Expanded Hidden Dimensions\n",
        "- The early structure `100‚Üí100` is expanded to `256‚Üí128` to enhance nonlinear representation capacity.\n",
        "\n",
        "#### (2) BatchNorm + Activation Enhancement\n",
        "- Add **Batch Normalization** after each linear layer to stabilize training.  \n",
        "- Activation combination: use **SiLU** in the first layer (smooth gradients, faster convergence) and **ReLU** in the second (better sparsity).\n",
        "\n",
        "#### (3) Residual Bottleneck Block\n",
        "- Introduce a lightweight residual block within the 256-dimensional layer: `256 ‚Üí 64 ‚Üí 256`.  \n",
        "- Structure: `BN ‚Üí SiLU ‚Üí Linear ‚Üí BN ‚Üí SiLU ‚Üí Linear`, followed by a pre-activation residual connection `x + h`.\n",
        "\n",
        "#### (4) Regularization on the Classification Head\n",
        "- Apply **Weight Normalization** to the final layer `Linear(128‚Üí10)` to reduce scale instability.  \n",
        "- Disable it before quantization for compatibility.\n",
        "\n",
        "> In addition, **Label Smoothing (Œµ=0.05)** is introduced to prevent overconfidence on single labels and improve generalization across label-permuted tasks."
      ],
      "metadata": {
        "id": "8GDlOy1FLZNc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from SD.utils.model import _MLP_ResBN,Bottleneck  # SiLU+BN / ReLU / Bottleneck / WeightNorm\n",
        "from SD.utils.loss import SmoothCE #LableSmoothing\n",
        "\n",
        "def _train_one_task(model, X_tr_np, y_tr_np, *, epochs=3, batch_size=128, lr=1e-3):\n",
        "    Xtr = torch.from_numpy(X_tr_np).float() / 255.0\n",
        "    ytr = torch.from_numpy(np.asarray(y_tr_np).reshape(-1)).long()\n",
        "    ds = torch.utils.data.TensorDataset(Xtr, ytr)\n",
        "    loader = torch.utils.data.DataLoader(\n",
        "        ds, batch_size=batch_size, shuffle=True, drop_last=False,\n",
        "        num_workers=0, pin_memory=False)\n",
        "    opt  = torch.optim.RMSprop(model.parameters(), lr=lr, alpha=0.99, momentum=0.0, centered=False, weight_decay=0.0)\n",
        "    crit = SmoothCE(eps=0.05, num_classes=10)\n",
        "    model.train()\n",
        "    for _ in range(epochs):\n",
        "        for xb, yb in loader:\n",
        "            opt.zero_grad(set_to_none=True)\n",
        "            logits = model(xb.view(xb.size(0), -1))\n",
        "            loss = crit(logits, yb)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "@torch.no_grad()\n",
        "\n",
        "def _predict(model, X_te_np):\n",
        "    Xte = torch.from_numpy(X_te_np).float() / 255.0\n",
        "    model.eval()\n",
        "    bs = 4096\n",
        "    outs = []\n",
        "    for i in range(0, Xte.shape[0], bs):\n",
        "        logits = model(Xte[i:i+bs].view(-1, 28*28))\n",
        "        outs.append(torch.argmax(logits, dim=1).cpu().numpy())\n",
        "    return np.concatenate(outs, axis=0)\n",
        "env.reset()\n",
        "env.set_seed(42)\n",
        "\n",
        "accs, times = [], []\n",
        "\n",
        "print(\"Evaluating TorchMLP + FE + IMS (256‚Üí128, BN+SiLU/ReLU, Bottleneck, WN, LS Œµ=0.05)  (epochs=3, batch=128)\")\n",
        "print(\"=\" * 80)\n",
        "\n",
        "task_id = 1\n",
        "while True:\n",
        "    task = env.get_next_task()\n",
        "    if task is None:\n",
        "        break\n",
        "\n",
        "    # ---- Apply Feature Engineering (reuse previous FE) ----\n",
        "    Xtr = _fe_for_agent(task['X_train'])\n",
        "    Xte = _fe_for_agent(task['X_test'])\n",
        "\n",
        "    # ---- Build improved model ----\n",
        "    model = _MLP_ResBN(in_dim=784, out_dim=10)\n",
        "\n",
        "    # ---- Train (reuse existing training helper, just change loss) ----\n",
        "    t0 = time.time()\n",
        "    _train_one_task(model, Xtr, task['y_train'], epochs=3, batch_size=128, lr=1e-3)\n",
        "    preds = _predict(model, Xte)\n",
        "    elapsed = time.time() - t0\n",
        "\n",
        "    acc = env.evaluate(preds, task['y_test'])\n",
        "    accs.append(acc)\n",
        "    times.append(elapsed)\n",
        "\n",
        "    print(f\"Task {task_id}: Accuracy = {acc:.2%}, Time = {elapsed:.2f}s\")\n",
        "    task_id += 1\n",
        "\n",
        "print(\"\\nTorchMLP + FE + IMS Summary:\")\n",
        "print(f\"  Mean accuracy: {np.mean(accs):.2%} ¬± {np.std(accs):.2%}\")\n",
        "print(f\"  Total time: {np.sum(times):.2f}s\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "sY6BqhczG7V3",
        "outputId": "28956259-e8da-4f87-dd8e-f18512b35286"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating TorchMLP + FE + IMS (256‚Üí128, BN+SiLU/ReLU, Bottleneck, WN, LS Œµ=0.05)  (epochs=3, batch=128)\n",
            "================================================================================\n",
            "Task 1: Accuracy = 98.23%, Time = 15.88s\n",
            "Task 2: Accuracy = 98.31%, Time = 13.94s\n",
            "Task 3: Accuracy = 98.19%, Time = 14.84s\n",
            "Task 4: Accuracy = 98.05%, Time = 14.15s\n",
            "Task 5: Accuracy = 98.07%, Time = 14.96s\n",
            "Task 6: Accuracy = 98.07%, Time = 14.13s\n",
            "Task 7: Accuracy = 98.28%, Time = 14.44s\n",
            "Task 8: Accuracy = 98.06%, Time = 13.79s\n",
            "Task 9: Accuracy = 98.07%, Time = 13.88s\n",
            "Task 10: Accuracy = 98.13%, Time = 13.91s\n",
            "\n",
            "TorchMLP + FE + IMS Summary:\n",
            "  Mean accuracy: 98.15% ¬± 0.09%\n",
            "  Total time: 143.91s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4Ô∏è‚É£ Optimizer (OP)\n",
        "\n",
        "#### Comparison and Selection\n",
        "- Compared **Adam**, **SGD**, and **RMSprop**:\n",
        "  - Adam: fast convergence but unstable oscillations;  \n",
        "  - SGD: stable but slow;  \n",
        "  - ‚úÖ **RMSprop**: balanced speed and smoothness on CPU ‚Äî selected as the final optimizer. Adding a **Cosine Annealing scheduler** further smooths the loss curve and stabilizes validation accuracy.\n"
      ],
      "metadata": {
        "id": "KvgFEoEVRf4x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from SD.utils.warmcosine import WarmupCosine\n",
        "\n",
        "OPT_FNS = {\n",
        "    \"Adam\":    lambda p: torch.optim.Adam(p, lr=1e-3, betas=(0.9, 0.999), weight_decay=0.0),\n",
        "    \"SGD\":     lambda p: torch.optim.SGD(p, lr=1e-2, momentum=0.9, nesterov=False, weight_decay=0.0),\n",
        "    \"RMSprop\": lambda p: torch.optim.RMSprop(p, lr=1e-3, alpha=0.99, momentum=0.0, centered=False, weight_decay=0.0),\n",
        "}\n",
        "\n",
        "EPOCHS = 3\n",
        "BATCH  = 128\n",
        "\n",
        "def run_with_optimizer(opt_name, opt_fn):\n",
        "    env.reset()\n",
        "    env.set_seed(42)\n",
        "\n",
        "    accs, times = [], []\n",
        "\n",
        "    print(f\"\\nEvaluating TorchMLP + FE + IMS  (OPT={opt_name}, epochs={EPOCHS}, batch={BATCH})\")\n",
        "    print(\"=\" * 90)\n",
        "\n",
        "    task_id = 1\n",
        "    while True:\n",
        "        task = env.get_next_task()\n",
        "        if task is None:\n",
        "            break\n",
        "\n",
        "        # ---- Feature Engineering (reuse) ----\n",
        "        Xtr = _fe_for_agent(task['X_train'])\n",
        "        Xte = _fe_for_agent(task['X_test'])\n",
        "\n",
        "        # ---- Build model (reuse IMS) ----\n",
        "        model = _MLP_ResBN(in_dim=784, out_dim=10)\n",
        "        crit  = SmoothCE(eps=0.05, num_classes=10)\n",
        "\n",
        "        # ---- Dataloader (same as step 3) ----\n",
        "        Xtr_t = torch.from_numpy(Xtr).float() / 255.0\n",
        "        ytr_t = torch.from_numpy(np.asarray(task['y_train']).reshape(-1)).long()\n",
        "        ds    = torch.utils.data.TensorDataset(Xtr_t, ytr_t)\n",
        "        loader= torch.utils.data.DataLoader(ds, batch_size=BATCH, shuffle=True, drop_last=False,\n",
        "                                            num_workers=0, pin_memory=False)\n",
        "\n",
        "        # ---- Train with chosen optimizer ----\n",
        "        opt = opt_fn(model.parameters())\n",
        "        sch = None\n",
        "        if opt_name == \"RMSprop\":\n",
        "            sch = WarmupCosine(opt, total_epochs=EPOCHS, warmup_epochs=1)\n",
        "\n",
        "        t0  = time.time()\n",
        "        model.train()\n",
        "        for _ in range(EPOCHS):\n",
        "            for xb, yb in loader:\n",
        "                opt.zero_grad(set_to_none=True)\n",
        "                logits = model(xb.view(xb.size(0), -1))\n",
        "                loss   = crit(logits, yb)\n",
        "                loss.backward()\n",
        "                opt.step()\n",
        "            if sch is not None:\n",
        "                sch.step()\n",
        "\n",
        "        # ---- Predict (same as step 3) ----\n",
        "        @torch.no_grad()\n",
        "        def _predict_batch(X_te_np):\n",
        "            Xte_t = torch.from_numpy(X_te_np).float() / 255.0\n",
        "            model.eval()\n",
        "            bs = 4096\n",
        "            outs = []\n",
        "            for i in range(0, Xte_t.shape[0], bs):\n",
        "                logits = model(Xte_t[i:i+bs].view(-1, 28*28))\n",
        "                outs.append(torch.argmax(logits, dim=1).cpu().numpy())\n",
        "            return np.concatenate(outs, axis=0)\n",
        "\n",
        "        preds   = _predict_batch(Xte)\n",
        "        elapsed = time.time() - t0\n",
        "\n",
        "        acc = env.evaluate(preds, task['y_test'])\n",
        "        accs.append(acc)\n",
        "        times.append(elapsed)\n",
        "\n",
        "        print(f\"Task {task_id}: Accuracy = {acc:.2%}, Time = {elapsed:.2f}s\")\n",
        "        task_id += 1\n",
        "\n",
        "    print(f\"\\n{opt_name} Summary:\")\n",
        "    print(f\"  Mean accuracy: {np.mean(accs):.2%} ¬± {np.std(accs):.2%}\")\n",
        "    print(f\"  Total time: {np.sum(times):.2f}s\")\n",
        "\n",
        "    return {\n",
        "        \"optimizer\": opt_name,\n",
        "        \"mean_acc\":  float(np.mean(accs)),\n",
        "        \"std_acc\":   float(np.std(accs)),\n",
        "        \"total_time\":float(np.sum(times)),\n",
        "        \"n_tasks\":   len(accs),\n",
        "    }\n",
        "\n",
        "# -------- Run all three and tabulate --------\n",
        "results = []\n",
        "for name, fn in OPT_FNS.items():\n",
        "    res = run_with_optimizer(name, fn)\n",
        "    results.append(res)\n",
        "\n",
        "df = pd.DataFrame(results)\n",
        "df = df[[\"optimizer\", \"n_tasks\", \"mean_acc\", \"std_acc\", \"total_time\"]]\n",
        "df[\"mean_acc(%)\"] = (df[\"mean_acc\"] * 100).round(2)\n",
        "df[\"std_acc(%)\"]  = (df[\"std_acc\"]  * 100).round(2)\n",
        "df[\"total_time(s)\"] = df[\"total_time\"].round(2)\n",
        "df = df.drop(columns=[\"mean_acc\", \"std_acc\", \"total_time\"])\n",
        "\n",
        "print(\"\\n=== Optimizer Comparison (Step 4) ===\")\n",
        "print(df.to_string(index=False))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "7A6xLJ5XGeR0",
        "outputId": "e7e5ce93-4df3-405b-fa9c-b6536e36d35c"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating TorchMLP + FE + IMS  (OPT=Adam, epochs=3, batch=128)\n",
            "==========================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/utils/weight_norm.py:144: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
            "  WeightNorm.apply(module, name, dim)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task 1: Accuracy = 98.12%, Time = 15.04s\n",
            "Task 2: Accuracy = 98.28%, Time = 15.28s\n",
            "Task 3: Accuracy = 98.23%, Time = 17.24s\n",
            "Task 4: Accuracy = 98.12%, Time = 14.86s\n",
            "Task 5: Accuracy = 98.02%, Time = 14.65s\n",
            "Task 6: Accuracy = 98.03%, Time = 14.79s\n",
            "Task 7: Accuracy = 98.02%, Time = 14.83s\n",
            "Task 8: Accuracy = 98.18%, Time = 14.77s\n",
            "Task 9: Accuracy = 98.35%, Time = 14.88s\n",
            "Task 10: Accuracy = 98.21%, Time = 14.84s\n",
            "\n",
            "Adam Summary:\n",
            "  Mean accuracy: 98.16% ¬± 0.11%\n",
            "  Total time: 151.19s\n",
            "\n",
            "Evaluating TorchMLP + FE + IMS  (OPT=SGD, epochs=3, batch=128)\n",
            "==========================================================================================\n",
            "Task 1: Accuracy = 97.62%, Time = 13.19s\n",
            "Task 2: Accuracy = 97.44%, Time = 12.86s\n",
            "Task 3: Accuracy = 97.41%, Time = 12.83s\n",
            "Task 4: Accuracy = 97.26%, Time = 12.64s\n",
            "Task 5: Accuracy = 97.78%, Time = 13.32s\n",
            "Task 6: Accuracy = 97.59%, Time = 12.94s\n",
            "Task 7: Accuracy = 97.39%, Time = 13.83s\n",
            "Task 8: Accuracy = 97.57%, Time = 13.58s\n",
            "Task 9: Accuracy = 97.47%, Time = 13.46s\n",
            "Task 10: Accuracy = 97.44%, Time = 14.41s\n",
            "\n",
            "SGD Summary:\n",
            "  Mean accuracy: 97.50% ¬± 0.14%\n",
            "  Total time: 133.06s\n",
            "\n",
            "Evaluating TorchMLP + FE + IMS  (OPT=RMSprop, epochs=3, batch=128)\n",
            "==========================================================================================\n",
            "Task 1: Accuracy = 98.39%, Time = 13.83s\n",
            "Task 2: Accuracy = 98.43%, Time = 13.84s\n",
            "Task 3: Accuracy = 98.23%, Time = 13.91s\n",
            "Task 4: Accuracy = 98.25%, Time = 13.89s\n",
            "Task 5: Accuracy = 98.36%, Time = 14.50s\n",
            "Task 6: Accuracy = 98.34%, Time = 14.61s\n",
            "Task 7: Accuracy = 98.39%, Time = 14.32s\n",
            "Task 8: Accuracy = 98.39%, Time = 13.86s\n",
            "Task 9: Accuracy = 98.48%, Time = 14.18s\n",
            "Task 10: Accuracy = 98.22%, Time = 14.38s\n",
            "\n",
            "RMSprop Summary:\n",
            "  Mean accuracy: 98.35% ¬± 0.08%\n",
            "  Total time: 141.32s\n",
            "\n",
            "=== Optimizer Comparison (Step 4) ===\n",
            "optimizer  n_tasks  mean_acc(%)  std_acc(%)  total_time(s)\n",
            "     Adam       10        98.16        0.11         151.19\n",
            "      SGD       10        97.50        0.14         133.06\n",
            "  RMSprop       10        98.35        0.08         141.32\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5Ô∏è‚É£ Model Compression (MC)\n",
        "\n",
        "During the inference stage, to further improve speed and efficiency under CPU constraints, two lightweight compression techniques were tested:  \n",
        "- **Dynamic INT8 Quantization**: Applied dynamic quantization to all fully connected layers, significantly boosting inference speed with almost no loss in accuracy;  \n",
        "- **Prune40% + INT8**: Performed 40% pruning before quantization, achieving faster inference but with a some accuracy drop.  \n",
        "\n",
        "**Dynamic INT8** worked remarkably well on our model!  \n",
        "We ultimately adopted it as the deployment scheme, achieving substantial acceleration in inference while maintaining stable accuracy.  \n",
        "Under certain heavier parameter settings, Dynamic INT8 even reduced inference time by more than tenfold without any loss in precision.  \n",
        "I believe this was the key factor that allowed our model to maintain competitive accuracy while running significantly faster than other approaches.\n"
      ],
      "metadata": {
        "id": "v2eYxxafU_3O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def _strip_weight_norms(model):\n",
        "    for m in model.modules():\n",
        "        try:\n",
        "            nn.utils.remove_weight_norm(m, name='weight')\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "def _train_rmsprop_warmcosine(model, Xtr_np, ytr_np, *, epochs=3, batch_size=128, lr=1e-3):\n",
        "    Xtr_t = torch.from_numpy(Xtr_np).float() / 255.0\n",
        "    ytr_t = torch.from_numpy(np.asarray(ytr_np).reshape(-1)).long()\n",
        "    ds    = torch.utils.data.TensorDataset(Xtr_t, ytr_t)\n",
        "    loader= torch.utils.data.DataLoader(ds, batch_size=batch_size, shuffle=True, drop_last=False,\n",
        "                                        num_workers=0, pin_memory=False)\n",
        "    opt   = torch.optim.RMSprop(model.parameters(), lr=lr, alpha=0.99, momentum=0.0, centered=False, weight_decay=0.0)\n",
        "    sched = WarmupCosine(opt, total_epochs=epochs, warmup_epochs=1)\n",
        "    crit  = SmoothCE(eps=0.05, num_classes=10)\n",
        "\n",
        "    model.train()\n",
        "    for _ in range(epochs):\n",
        "        for xb, yb in loader:\n",
        "            opt.zero_grad(set_to_none=True)\n",
        "            logits = model(xb.view(xb.size(0), -1))\n",
        "            loss   = crit(logits, yb)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "        sched.step()\n",
        "\n",
        "def _run_rmsprop_with_compressor(label, compress_mode, *, epochs=3, batch_size=128, lr=1e-3):\n",
        "\n",
        "    env.reset()\n",
        "    env.set_seed(42)\n",
        "\n",
        "    print(f\"\\nEvaluating [{label}]  RMSprop+WarmCosine + FE + IMS  (epochs={epochs}, batch={batch_size})\")\n",
        "    print(\"=\" * 96)\n",
        "\n",
        "    accs, times = [], []\n",
        "    task_id = 1\n",
        "    while True:\n",
        "        task = env.get_next_task()\n",
        "        if task is None:\n",
        "            break\n",
        "\n",
        "        # ---- FEÔºà‰∏éÁ¨¨‰∏âÊ≠•‰∏ÄËá¥Ôºâ----\n",
        "        Xtr = _fe_for_agent(task['X_train'])\n",
        "        Xte = _fe_for_agent(task['X_test'])\n",
        "\n",
        "        # ---- build the model ----\n",
        "        model = _MLP_ResBN(in_dim=784, out_dim=10)\n",
        "\n",
        "        # ---- train ----\n",
        "        t0 = time.time()\n",
        "        _train_rmsprop_warmcosine(model, Xtr, task['y_train'], epochs=epochs, batch_size=batch_size, lr=lr)\n",
        "\n",
        "        # ---- compressor ----\n",
        "        if compress_mode == 'int8':\n",
        "            # remove WN\n",
        "            _strip_weight_norms(model)\n",
        "            try:\n",
        "                model_eval = apply_dynamic_int8_quantization(model)\n",
        "            except Exception:\n",
        "                model_eval = torch.ao.quantization.quantize_dynamic(model, {nn.Linear}, dtype=torch.qint8, inplace=False)\n",
        "\n",
        "        elif compress_mode == 'prune_int8':\n",
        "            _strip_weight_norms(model)\n",
        "            # in_place=True avoid deepcopy trigger the restriction of WN\n",
        "            model_q, _rep = prune40_int8(model, amount=0.40, exclude_head=True, in_place=True)\n",
        "            model_eval = model_q\n",
        "        else:\n",
        "            raise ValueError(f\"Unknown compress_mode: {compress_mode}\")\n",
        "\n",
        "        preds   = _predict(model_eval, Xte)\n",
        "        elapsed = time.time() - t0\n",
        "\n",
        "        accs.append(env.evaluate(preds, task['y_test']))\n",
        "        times.append(elapsed)\n",
        "        print(f\"Task {task_id}: Accuracy = {accs[-1]:.2%}, Time = {elapsed:.2f}s\")\n",
        "        task_id += 1\n",
        "\n",
        "    mean_acc = float(np.mean(accs))\n",
        "    std_acc  = float(np.std(accs))\n",
        "    total_t  = float(np.sum(times))\n",
        "\n",
        "    print(f\"\\n[{label}] Summary:\")\n",
        "    print(f\"  Mean accuracy: {mean_acc:.2%} ¬± {std_acc:.2%}\")\n",
        "    print(f\"  Total time: {total_t:.2f}s\")\n",
        "\n",
        "    return {\n",
        "        \"variant\": label,\n",
        "        \"mean_acc\":  mean_acc,\n",
        "        \"std_acc\":   std_acc,\n",
        "        \"total_time\": total_t,\n",
        "        \"n_tasks\":   len(accs),\n",
        "    }\n",
        "\n",
        "# ------------------ run the model with 2 compressor ------------------\n",
        "res_int8       = _run_rmsprop_with_compressor(\"Dynamic INT8\",    \"int8\",       epochs=3, batch_size=128, lr=1e-3)\n",
        "res_prune_int8 = _run_rmsprop_with_compressor(\"Prune40% + INT8\", \"prune_int8\", epochs=3, batch_size=128, lr=1e-3)\n",
        "\n",
        "# ------------------ comparison table ------------------\n",
        "results = [res_int8, res_prune_int8]\n",
        "df = pd.DataFrame(results)\n",
        "df[\"mean_acc(%)\"]   = (df[\"mean_acc\"] * 100).round(2)\n",
        "df[\"std_acc(%)\"]    = (df[\"std_acc\"]  * 100).round(2)\n",
        "df[\"total_time(s)\"] = df[\"total_time\"].round(2)\n",
        "df = df[[\"variant\", \"n_tasks\", \"mean_acc(%)\", \"std_acc(%)\", \"total_time(s)\"]]\n",
        "\n",
        "print(\"\\n=== RMSprop+WarmCosine with Compressors ‚Äî Comparison ===\")\n",
        "print(df.to_string(index=False))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "39-d-LDtBMmW",
        "outputId": "a1e8246b-6718-49c4-9985-62b24b9417d0"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating [Dynamic INT8]  RMSprop+WarmCosine + FE + IMS  (epochs=3, batch=128)\n",
            "================================================================================================\n",
            "Task 1: Accuracy = 98.45%, Time = 15.27s\n",
            "Task 2: Accuracy = 98.31%, Time = 14.38s\n",
            "Task 3: Accuracy = 98.26%, Time = 16.50s\n",
            "Task 4: Accuracy = 98.21%, Time = 15.19s\n",
            "Task 5: Accuracy = 98.26%, Time = 17.70s\n",
            "Task 6: Accuracy = 98.43%, Time = 17.06s\n",
            "Task 7: Accuracy = 98.38%, Time = 18.77s\n",
            "Task 8: Accuracy = 98.49%, Time = 16.38s\n",
            "Task 9: Accuracy = 98.30%, Time = 15.90s\n",
            "Task 10: Accuracy = 98.17%, Time = 15.09s\n",
            "\n",
            "[Dynamic INT8] Summary:\n",
            "  Mean accuracy: 98.33% ¬± 0.10%\n",
            "  Total time: 162.24s\n",
            "\n",
            "Evaluating [Prune40% + INT8]  RMSprop+WarmCosine + FE + IMS  (epochs=3, batch=128)\n",
            "================================================================================================\n",
            "Task 1: Accuracy = 98.09%, Time = 15.16s\n",
            "Task 2: Accuracy = 98.09%, Time = 16.44s\n",
            "Task 3: Accuracy = 97.93%, Time = 14.53s\n",
            "Task 4: Accuracy = 98.18%, Time = 16.25s\n",
            "Task 5: Accuracy = 98.23%, Time = 14.27s\n",
            "Task 6: Accuracy = 97.99%, Time = 16.15s\n",
            "Task 7: Accuracy = 97.91%, Time = 14.50s\n",
            "Task 8: Accuracy = 97.99%, Time = 15.70s\n",
            "Task 9: Accuracy = 98.20%, Time = 14.67s\n",
            "Task 10: Accuracy = 98.25%, Time = 15.09s\n",
            "\n",
            "[Prune40% + INT8] Summary:\n",
            "  Mean accuracy: 98.09% ¬± 0.12%\n",
            "  Total time: 152.76s\n",
            "\n",
            "=== RMSprop+WarmCosine with Compressors ‚Äî Comparison ===\n",
            "        variant  n_tasks  mean_acc(%)  std_acc(%)  total_time(s)\n",
            "   Dynamic INT8       10        98.33        0.10         162.24\n",
            "Prune40% + INT8       10        98.09        0.12         152.76\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### 6Ô∏è‚É£ Hyperparameter Tuning and Final Configuration\n",
        "\n",
        "A grid search was conducted over:  \n",
        "`epochs ‚àà {5, 7, 10, 15}`, `batch_size ‚àà {100, 128}`  \n"
      ],
      "metadata": {
        "id": "7QkgXvV5zdAD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def _strip_weight_norms(model):\n",
        "    for m in model.modules():\n",
        "        try:\n",
        "            nn.utils.remove_weight_norm(m, name='weight')\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "def _train_rmsprop_warmcosine(model, Xtr_np, ytr_np, *, epochs=3, batch_size=128, lr=1e-3):\n",
        "    Xtr_t = torch.from_numpy(Xtr_np).float() / 255.0\n",
        "    ytr_t = torch.from_numpy(np.asarray(ytr_np).reshape(-1)).long()\n",
        "    ds    = torch.utils.data.TensorDataset(Xtr_t, ytr_t)\n",
        "    loader= torch.utils.data.DataLoader(ds, batch_size=batch_size, shuffle=True, drop_last=False,\n",
        "                                        num_workers=0, pin_memory=False)\n",
        "    opt   = torch.optim.RMSprop(model.parameters(), lr=lr, alpha=0.99, momentum=0.0, centered=False, weight_decay=0.0)\n",
        "    sched = WarmupCosine(opt, total_epochs=epochs, warmup_epochs=1)\n",
        "    crit  = SmoothCE(eps=0.05, num_classes=10)\n",
        "\n",
        "    model.train()\n",
        "    for _ in range(epochs):\n",
        "        for xb, yb in loader:\n",
        "            opt.zero_grad(set_to_none=True)\n",
        "            logits = model(xb.view(xb.size(0), -1))\n",
        "            loss   = crit(logits, yb)\n",
        "            loss.backward()\n",
        "            opt.step()\n",
        "        sched.step()\n",
        "\n",
        "def _to_int8(model):\n",
        "    _strip_weight_norms(model)\n",
        "    try:\n",
        "        return apply_dynamic_int8_quantization(model)\n",
        "    except Exception:\n",
        "        return torch.ao.quantization.quantize_dynamic(\n",
        "            model, {nn.Linear}, dtype=torch.qint8, inplace=False\n",
        "        )\n",
        "\n",
        "def _run_config(epochs, batch_size, lr=1e-3):\n",
        "    env.reset()\n",
        "    env.set_seed(42)\n",
        "\n",
        "    print(f\"\\nEvaluating (epochs={epochs}, batch={batch_size})  RMSprop+WarmCosine + FE + IMS + Dynamic INT8\")\n",
        "    print(\"=\" * 96)\n",
        "\n",
        "    accs, times = [], []\n",
        "    tid = 1\n",
        "    while True:\n",
        "        task = env.get_next_task()\n",
        "        if task is None:\n",
        "            break\n",
        "\n",
        "        # FE\n",
        "        Xtr = _fe_for_agent(task['X_train'])\n",
        "        Xte = _fe_for_agent(task['X_test'])\n",
        "\n",
        "        # model\n",
        "        model = _MLP_ResBN(in_dim=784, out_dim=10)\n",
        "\n",
        "        # train\n",
        "        t0 = time.time()\n",
        "        _train_rmsprop_warmcosine(model, Xtr, task['y_train'], epochs=epochs, batch_size=batch_size, lr=lr)\n",
        "\n",
        "        # compress: dynamic INT8\n",
        "        model_q = _to_int8(model)\n",
        "\n",
        "        # predict\n",
        "        preds   = _predict(model_q, Xte)\n",
        "        elapsed = time.time() - t0\n",
        "\n",
        "        acc = env.evaluate(preds, task['y_test'])\n",
        "        accs.append(acc); times.append(elapsed)\n",
        "        print(f\"Task {tid}: Accuracy = {acc:.2%}, Time = {elapsed:.2f}s\")\n",
        "        tid += 1\n",
        "\n",
        "    mean_acc = float(np.mean(accs))\n",
        "    std_acc  = float(np.std(accs))\n",
        "    total_t  = float(np.sum(times))\n",
        "\n",
        "    print(f\"\\n(epochs={epochs}, batch={batch_size}) Summary:\")\n",
        "    print(f\"  Mean accuracy: {mean_acc:.2%} ¬± {std_acc:.2%}\")\n",
        "    print(f\"  Total time: {total_t:.2f}s\")\n",
        "\n",
        "    return {\n",
        "        \"epochs\": epochs,\n",
        "        \"batch_size\": batch_size,\n",
        "        \"n_tasks\": len(accs),\n",
        "        \"mean_acc\":  mean_acc,\n",
        "        \"std_acc\":   std_acc,\n",
        "        \"total_time\": total_t,\n",
        "    }\n",
        "\n",
        "# --------- run 8 group ---------\n",
        "grid_epochs = [5, 7, 10, 15]\n",
        "grid_batch  = [100, 128]\n",
        "\n",
        "all_results = []\n",
        "for ep in grid_epochs:\n",
        "    for bs in grid_batch:\n",
        "        all_results.append(_run_config(ep, bs, lr=1e-3))\n",
        "\n",
        "# --------- comparison table ---------\n",
        "df = pd.DataFrame(all_results)\n",
        "df[\"mean_acc(%)\"]   = (df[\"mean_acc\"] * 100).round(2)\n",
        "df[\"std_acc(%)\"]    = (df[\"std_acc\"]  * 100).round(2)\n",
        "df[\"total_time(s)\"] = df[\"total_time\"].round(2)\n",
        "df = df[[\"epochs\", \"batch_size\", \"n_tasks\", \"mean_acc(%)\", \"std_acc(%)\", \"total_time(s)\"]]\n",
        "df = df.sort_values(by=[\"mean_acc(%)\",\"total_time(s)\"], ascending=[False, True])\n",
        "\n",
        "print(\"\\n=== Grid Search: RMSprop+WarmCosine + Dynamic INT8 ===\")\n",
        "print(df.to_string(index=False))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "fk0gP2IFzDaE",
        "outputId": "79d1750a-c76d-40b0-bf6d-e3a8767b81b1"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluating (epochs=5, batch=100)  RMSprop+WarmCosine + FE + IMS + Dynamic INT8\n",
            "================================================================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/utils/weight_norm.py:144: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
            "  WeightNorm.apply(module, name, dim)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Task 1: Accuracy = 98.49%, Time = 26.75s\n",
            "Task 2: Accuracy = 98.59%, Time = 27.79s\n",
            "Task 3: Accuracy = 98.64%, Time = 26.55s\n",
            "Task 4: Accuracy = 98.54%, Time = 27.07s\n",
            "Task 5: Accuracy = 98.62%, Time = 26.66s\n",
            "Task 6: Accuracy = 98.56%, Time = 26.82s\n",
            "Task 7: Accuracy = 98.54%, Time = 29.11s\n",
            "Task 8: Accuracy = 98.55%, Time = 27.25s\n",
            "Task 9: Accuracy = 98.56%, Time = 26.51s\n",
            "Task 10: Accuracy = 98.60%, Time = 26.55s\n",
            "\n",
            "(epochs=5, batch=100) Summary:\n",
            "  Mean accuracy: 98.57% ¬± 0.04%\n",
            "  Total time: 271.06s\n",
            "\n",
            "Evaluating (epochs=5, batch=128)  RMSprop+WarmCosine + FE + IMS + Dynamic INT8\n",
            "================================================================================================\n",
            "Task 1: Accuracy = 98.50%, Time = 23.97s\n",
            "Task 2: Accuracy = 98.55%, Time = 23.80s\n",
            "Task 3: Accuracy = 98.56%, Time = 25.60s\n",
            "Task 4: Accuracy = 98.62%, Time = 23.95s\n",
            "Task 5: Accuracy = 98.55%, Time = 26.16s\n",
            "Task 6: Accuracy = 98.65%, Time = 27.07s\n",
            "Task 7: Accuracy = 98.59%, Time = 26.98s\n",
            "Task 8: Accuracy = 98.58%, Time = 24.82s\n",
            "Task 9: Accuracy = 98.48%, Time = 23.02s\n",
            "Task 10: Accuracy = 98.56%, Time = 24.30s\n",
            "\n",
            "(epochs=5, batch=128) Summary:\n",
            "  Mean accuracy: 98.56% ¬± 0.05%\n",
            "  Total time: 249.67s\n",
            "\n",
            "Evaluating (epochs=7, batch=100)  RMSprop+WarmCosine + FE + IMS + Dynamic INT8\n",
            "================================================================================================\n",
            "Task 1: Accuracy = 98.58%, Time = 36.75s\n",
            "Task 2: Accuracy = 98.60%, Time = 37.50s\n",
            "Task 3: Accuracy = 98.57%, Time = 38.28s\n",
            "Task 4: Accuracy = 98.65%, Time = 37.48s\n",
            "Task 5: Accuracy = 98.56%, Time = 39.89s\n",
            "Task 6: Accuracy = 98.57%, Time = 37.17s\n",
            "Task 7: Accuracy = 98.64%, Time = 37.13s\n",
            "Task 8: Accuracy = 98.76%, Time = 42.33s\n",
            "Task 9: Accuracy = 98.61%, Time = 40.25s\n",
            "Task 10: Accuracy = 98.69%, Time = 38.96s\n",
            "\n",
            "(epochs=7, batch=100) Summary:\n",
            "  Mean accuracy: 98.62% ¬± 0.06%\n",
            "  Total time: 385.73s\n",
            "\n",
            "Evaluating (epochs=7, batch=128)  RMSprop+WarmCosine + FE + IMS + Dynamic INT8\n",
            "================================================================================================\n",
            "Task 1: Accuracy = 98.55%, Time = 32.81s\n",
            "Task 2: Accuracy = 98.64%, Time = 32.96s\n",
            "Task 3: Accuracy = 98.69%, Time = 33.00s\n",
            "Task 4: Accuracy = 98.65%, Time = 32.94s\n",
            "Task 5: Accuracy = 98.58%, Time = 32.44s\n",
            "Task 6: Accuracy = 98.50%, Time = 32.19s\n",
            "Task 7: Accuracy = 98.69%, Time = 36.67s\n",
            "Task 8: Accuracy = 98.63%, Time = 33.48s\n",
            "Task 9: Accuracy = 98.66%, Time = 32.18s\n",
            "Task 10: Accuracy = 98.54%, Time = 34.14s\n",
            "\n",
            "(epochs=7, batch=128) Summary:\n",
            "  Mean accuracy: 98.61% ¬± 0.06%\n",
            "  Total time: 332.82s\n",
            "\n",
            "Evaluating (epochs=10, batch=100)  RMSprop+WarmCosine + FE + IMS + Dynamic INT8\n",
            "================================================================================================\n",
            "Task 1: Accuracy = 98.56%, Time = 59.39s\n",
            "Task 2: Accuracy = 98.68%, Time = 57.58s\n",
            "Task 3: Accuracy = 98.75%, Time = 53.25s\n",
            "Task 4: Accuracy = 98.73%, Time = 56.02s\n",
            "Task 5: Accuracy = 98.71%, Time = 53.30s\n",
            "Task 6: Accuracy = 98.65%, Time = 53.64s\n",
            "Task 7: Accuracy = 98.72%, Time = 57.65s\n",
            "Task 8: Accuracy = 98.61%, Time = 59.85s\n",
            "Task 9: Accuracy = 98.64%, Time = 53.53s\n",
            "Task 10: Accuracy = 98.72%, Time = 54.91s\n",
            "\n",
            "(epochs=10, batch=100) Summary:\n",
            "  Mean accuracy: 98.68% ¬± 0.06%\n",
            "  Total time: 559.12s\n",
            "\n",
            "Evaluating (epochs=10, batch=128)  RMSprop+WarmCosine + FE + IMS + Dynamic INT8\n",
            "================================================================================================\n",
            "Task 1: Accuracy = 98.63%, Time = 47.47s\n",
            "Task 2: Accuracy = 98.79%, Time = 47.64s\n",
            "Task 3: Accuracy = 98.68%, Time = 50.56s\n",
            "Task 4: Accuracy = 98.66%, Time = 53.07s\n",
            "Task 5: Accuracy = 98.74%, Time = 47.97s\n",
            "Task 6: Accuracy = 98.71%, Time = 52.07s\n",
            "Task 7: Accuracy = 98.66%, Time = 52.13s\n",
            "Task 8: Accuracy = 98.60%, Time = 48.94s\n",
            "Task 9: Accuracy = 98.61%, Time = 49.99s\n",
            "Task 10: Accuracy = 98.73%, Time = 60.80s\n",
            "\n",
            "(epochs=10, batch=128) Summary:\n",
            "  Mean accuracy: 98.68% ¬± 0.06%\n",
            "  Total time: 510.65s\n",
            "\n",
            "Evaluating (epochs=15, batch=100)  RMSprop+WarmCosine + FE + IMS + Dynamic INT8\n",
            "================================================================================================\n",
            "Task 1: Accuracy = 98.73%, Time = 97.54s\n",
            "Task 2: Accuracy = 98.67%, Time = 87.88s\n",
            "Task 3: Accuracy = 98.79%, Time = 82.69s\n",
            "Task 4: Accuracy = 98.65%, Time = 81.46s\n",
            "Task 5: Accuracy = 98.55%, Time = 80.11s\n",
            "Task 6: Accuracy = 98.64%, Time = 80.86s\n",
            "Task 7: Accuracy = 98.58%, Time = 81.78s\n",
            "Task 8: Accuracy = 98.73%, Time = 79.13s\n",
            "Task 9: Accuracy = 98.74%, Time = 80.02s\n",
            "Task 10: Accuracy = 98.77%, Time = 79.87s\n",
            "\n",
            "(epochs=15, batch=100) Summary:\n",
            "  Mean accuracy: 98.69% ¬± 0.08%\n",
            "  Total time: 831.34s\n",
            "\n",
            "Evaluating (epochs=15, batch=128)  RMSprop+WarmCosine + FE + IMS + Dynamic INT8\n",
            "================================================================================================\n",
            "Task 1: Accuracy = 98.73%, Time = 70.11s\n",
            "Task 2: Accuracy = 98.66%, Time = 70.03s\n",
            "Task 3: Accuracy = 98.59%, Time = 74.76s\n",
            "Task 4: Accuracy = 98.69%, Time = 71.05s\n",
            "Task 5: Accuracy = 98.76%, Time = 69.96s\n",
            "Task 6: Accuracy = 98.65%, Time = 70.06s\n",
            "Task 7: Accuracy = 98.72%, Time = 70.29s\n",
            "Task 8: Accuracy = 98.70%, Time = 70.59s\n",
            "Task 9: Accuracy = 98.64%, Time = 73.72s\n",
            "Task 10: Accuracy = 98.60%, Time = 70.66s\n",
            "\n",
            "(epochs=15, batch=128) Summary:\n",
            "  Mean accuracy: 98.67% ¬± 0.05%\n",
            "  Total time: 711.23s\n",
            "\n",
            "=== Grid Search: RMSprop+WarmCosine + Dynamic INT8 ===\n",
            " epochs  batch_size  n_tasks  mean_acc(%)  std_acc(%)  total_time(s)\n",
            "     15         100       10        98.69        0.08         831.34\n",
            "     10         128       10        98.68        0.06         510.65\n",
            "     10         100       10        98.68        0.06         559.12\n",
            "     15         128       10        98.67        0.05         711.23\n",
            "      7         100       10        98.62        0.06         385.73\n",
            "      7         128       10        98.61        0.06         332.82\n",
            "      5         100       10        98.57        0.04         271.06\n",
            "      5         128       10        98.56        0.05         249.67\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Among the eight experimental configurations, **`epochs=10, batch_size=128`** achieved the best balance between accuracy and runtime.  \n",
        "It reached a **mean accuracy of 98.68%**, one of the highest across all tests, while keeping the **average task time around 51 seconds**, safely below the 60-second evaluation limit.  \n",
        "Compared with higher epochs (e.g., 15), this setup maintained nearly identical accuracy but with significantly shorter runtime;  \n",
        "and compared with lower epochs (5 or 7), it achieved more stable and higher convergence with only a modest increase in time.  \n",
        "Therefore, **`epochs=10, batch_size=128`** was selected as the final configuration for submission.\n",
        "\n",
        "Moreover, the model actually performs much better online than it does here, it cost way less time than here."
      ],
      "metadata": {
        "id": "BCsMEPgZE23m"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚Ö¢ Reproduction of Best Submission"
      ],
      "metadata": {
        "id": "7D66pEl2crXk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from SD.agent import TorchMLP as BestAgent\n",
        "\n",
        "# Reset environment for fresh start\n",
        "env.reset()\n",
        "env.set_seed(42)\n",
        "\n",
        "best_agent = BestAgent(\n",
        "    output_dim=10,\n",
        "    seed=42,\n",
        "    epochs=10,\n",
        "    batch_size=128,\n",
        "    lr=1e-3,\n",
        "    val_ratio=0.2\n",
        ")\n",
        "\n",
        "best_accuracies = []\n",
        "best_times = []\n",
        "\n",
        "print(\"Evaluating Best Agent: TorchMLP + FE + SiLU + Bottleneck + WeightNorm + LS + WarmupCosine + Dynamic INT8\")\n",
        "print(\"=\" * 90)\n",
        "\n",
        "task_num = 1\n",
        "while True:\n",
        "    task = env.get_next_task()\n",
        "    if task is None:\n",
        "        break\n",
        "\n",
        "       best_agent.reset()\n",
        "\n",
        "    start_time = time.time()\n",
        "    best_agent.train(task['X_train'], task['y_train'])\n",
        "\n",
        "    best_agent.compress_dynamic_int8()\n",
        "\n",
        "    predictions = best_agent.predict(task['X_test'])\n",
        "    elapsed_time = time.time() - start_time\n",
        "\n",
        "    accuracy = env.evaluate(predictions, task['y_test'])\n",
        "    best_accuracies.append(accuracy)\n",
        "    best_times.append(elapsed_time)\n",
        "\n",
        "    print(f\"Task {task_num}: Accuracy = {accuracy:.2%}, Time = {elapsed_time:.2f}s\")\n",
        "    task_num += 1\n",
        "\n",
        "print(\"\\nBest Agent Summary:\")\n",
        "print(f\"  Mean accuracy: {np.mean(best_accuracies):.2%} ¬± {np.std(best_accuracies):.2%}\")\n",
        "print(f\"  Total time: {np.sum(best_times):.2f}s\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "-6eNBY8kqLT9",
        "outputId": "6f2fbc21-b0d6-4eef-96e2-f95b211790db"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/utils/weight_norm.py:144: FutureWarning: `torch.nn.utils.weight_norm` is deprecated in favor of `torch.nn.utils.parametrizations.weight_norm`.\n",
            "  WeightNorm.apply(module, name, dim)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating Best Agent: TorchMLP + FE + SiLU + Bottleneck + WeightNorm + LS + WarmupCosine + Dynamic INT8\n",
            "==========================================================================================\n",
            "Task 1: Accuracy = 98.55%, Time = 40.67s\n",
            "Task 2: Accuracy = 98.57%, Time = 38.33s\n",
            "Task 3: Accuracy = 98.51%, Time = 38.23s\n",
            "Task 4: Accuracy = 98.51%, Time = 38.44s\n",
            "Task 5: Accuracy = 98.50%, Time = 37.73s\n",
            "Task 6: Accuracy = 98.57%, Time = 38.74s\n",
            "Task 7: Accuracy = 98.39%, Time = 44.51s\n",
            "Task 8: Accuracy = 98.56%, Time = 38.67s\n",
            "Task 9: Accuracy = 98.51%, Time = 38.07s\n",
            "Task 10: Accuracy = 98.55%, Time = 38.96s\n",
            "\n",
            "Best Agent Summary:\n",
            "  Mean accuracy: 98.52% ¬± 0.05%\n",
            "  Total time: 392.33s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### üèÜ YeWeN / –ï–∫–∞—Ç–µ—Ä–∏–Ω–∞1\n",
        "\n",
        "> **TorchMLP (RMSprop + FE + SiLU + Bottleneck + WeightNorm + LabelSmoothing + WarmupCosine + Dynamic INT8)**\n",
        "\n",
        "\n",
        "The architecture expands from `256 ‚Üí 128` with **Batch Normalization**, **SiLU + ReLU** activations, and a **Bottleneck residual block** to enhance gradient flow and feature retention.  \n",
        "A **Weight Normalization** layer stabilizes training, while **Label Smoothing (Œµ=0.05)** improves robustness.\n",
        "\n",
        "On the optimization side, **RMSprop** was selected as the most stable CPU-friendly optimizer, combined with a **Warmup-Cosine scheduler** for smoother convergence.  \n",
        "During inference, **Dynamic INT8 quantization** compresses all linear layers, cutting memory usage and latency with minimal accuracy loss.\n",
        "\n",
        "This design achieves **98.65% mean accuracy in only ~21 seconds** on the Permuted MNIST benchmark, demonstrating an ideal balance between computational efficiency and predictive precision.  \n",
        "Overall, it is a **compact, high-performing, and deployable agent**, suitable for CPU-limited environments without sacrificing reliability.\n",
        "\n",
        "---\n",
        "\n",
        "**Final Configuration:**\n",
        "| Component | Description |\n",
        "|------------|--------------|\n",
        "| Architecture | `MLP(256‚Üí128)` + BatchNorm + SiLU/ReLU + Bottleneck |\n",
        "| Regularization | WeightNorm + Label Smoothing (Œµ=0.05) |\n",
        "| Optimizer | RMSprop (lr=1e-3, Œ±=0.99) |\n",
        "| Scheduler | WarmupCosine (20 epochs, warmup=1) |\n",
        "| Compression | Dynamic INT8 Quantization |\n",
        "| Training | Epochs = 10, Batch = 128 |\n",
        "| Mean Accuracy | **98.65%** |\n",
        "| Total Runtime | **21.0 s** |\n",
        "| Memory Usage | **~656 MB** |\n",
        "| Agent Name (ML-Arena) | **YeWeN / –ï–∫–∞—Ç–µ—Ä–∏–Ω–∞1** |\n"
      ],
      "metadata": {
        "id": "QKTOP03TdAzs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ‚Ö£ Failure Analysis & Next Steps\n"
      ],
      "metadata": {
        "id": "iAV7KG_rdLiN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Failure Analysis\n",
        "\n",
        "**1Ô∏è‚É£ Insufficient Utilization of Training Time**  \n",
        "The final model completed all tasks in about **21 seconds**, leaving nearly 40 seconds unused out of the 60-second evaluation limit.  \n",
        "This indicates that the computational budget was not fully exploited ‚Äî more training epochs, structural depth, or small-scale ensembles could be implemented to extract higher accuracy within the allowed runtime.\n",
        "\n",
        "\n",
        "**2Ô∏è‚É£ Excessive CPU Usage**  \n",
        "During multi-task evaluation, CPU utilization occasionally exceeded 140% (equivalent to two cores running at full load with slight oversubscription), suggesting suboptimal thread management and data loading. Possible improvements include:  \n",
        "- Reducing the number of `DataLoader` workers (`num_workers=0` or `1`) to minimize parallel overhead;  \n",
        "- Adjusting the `batch_size` to balance compute and memory bandwidth;  \n",
        "- Using `torch.set_num_threads(1)` before and after quantization to stabilize CPU usage.\n",
        "\n",
        "---\n",
        "\n",
        "## Improvement Directions and Future Work\n",
        "\n",
        "**1Ô∏è‚É£ Increase Epochs + Early Stopping Mechanism**  \n",
        "Since the model did not reach the time limit at 20 epochs, the training duration can be safely extended to **30 epochs or more**, combined with early stopping (e.g., `patience=3‚Äì5`) to prevent overfitting.  \n",
        "This would allow more thorough convergence without wasting resources, leading to smoother validation curves and more stable accuracy.\n",
        "\n",
        "\n",
        "**2Ô∏è‚É£ Dropout Regularization**  \n",
        "Introducing moderate **Dropout (p‚âà0.1‚Äì0.2)** in the bottleneck or hidden layers can prevent neuron co-adaptation and improve robustness against noise and permutation variations.  \n",
        "In a CPU-only setting, this lightweight regularization adds almost no computational cost while noticeably enhancing generalization and stability.\n",
        "\n",
        "\n",
        "**3Ô∏è‚É£ Ensemble Learning**  \n",
        "Training multiple lightweight models (using different random seeds or subsets of data) within the available time and averaging their predictions during inference can improve generalization.  \n",
        "Even under CPU constraints, such ensembling can provide meaningful gains by reducing variance and smoothing out random errors at low additional cost.\n",
        "\n",
        "\n",
        "**4Ô∏è‚É£ Meta-Learning**  \n",
        "Future work can explore meta-learning approaches such as\n",
        "\n"
      ],
      "metadata": {
        "id": "EeDZkRJw93Iy"
      }
    }
  ]
}